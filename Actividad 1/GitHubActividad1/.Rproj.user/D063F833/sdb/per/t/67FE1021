{
    "contents" : "---\ntitle: \"Forecasting Demand\"\nauthor: \"Natalia Clivio\"\ndate: \"November, 2014\"\noutput: pdf_document\n---\n\nThis code is for predict the CV subscribers data and write in a cvs file the forecasting and the modelÂ´s performance\n\n\n#Load and clean Data\nThe file loaded is the CV subscribers from 2005 up to 2014, for each service. The service offering by the company are:\nInternet residential and business, Video on demand and VoIP.\n\n````{r message=FALSE,warning=FALSE}\nlibrary(caret)\nlibrary(forecast)\nlibrary(grofit)\nlibrary(growthmodels)\n\nsubs<-read.csv(\"C:/Users/NataliaA/Documents/DataR/Subscribers_CV.csv\",header=TRUE,\n                sep=\";\",na.strings=\"NA\",dec=\",\")\ndata_subs<-na.exclude(subs[1:5])\n````\n\n*Falta actualizar los datos*\n````{r}\ndata_subs \n````\n\n\n#Data Preparation\n\n````{r message=FALSE,warning=FALSE}\ninTrain<-createDataPartition(y=data_subs$Year, p=0.75, list=FALSE)\ntraining<-data_subs[inTrain,]\ntesting<-data_subs[-inTrain,]\n````\n\n\n#Demand Models for Internet  Residential Subscribers\n\n````{r message=FALSE,warning=FALSE}\ntrainres<-data.frame(Year=training$Year,Subs=training$Internet_Res)\ntestres<-data.frame(Year=testing$Year,Subs=testing$Internet_Res)\n````\n\n \n##1.Predicting with Random Forest\n\n```{r message=FALSE, warning=FALSE}\nmodrf<-train(Subs~.,data=trainres,method=\"rf\",prox=TRUE)  #Model\npredrf <- predict(modrf, testres)                         #Prediction\n\nfore1<-data.frame(testres,Random_Forest=predrf)\nfore1\n```\n\n\n````{r echo=FALSE}\nplot(testres,xlab=\"Year\",ylab=\"Subscribers\",col=\"blue\",\n     main=\"Forecasting Plots\")\nlines(testres,lwd=1,col=\"blue\")\nlines(testres$Year,predrf,lwd=2,col=\"goldenrod4\")\nlegend(\"topleft\",legend=c(\"Subs\",\"Random Forest\"),\n       col=c(\"blue\",\"goldenrod4\"),lty=1,lwd=2)\n```\n\n\n##2. Predicting with Boosting\n\n```{r message=FALSE,warning=FALSE}\n\n#Boosted Generalized Additive Model\nmodbsgam <- train(Subs ~ ., method = \"gamboost\", data = trainres) \npredbsgam <- predict(modbsgam, testres)\n\n#Cubist\nmodbscub <- train(Subs ~ ., method = \"cubist\", data = trainres)  \npredbscub <- predict(modbscub, testres)\n\n#Boosted Smoothing Spline\nmodbsSm <- train(Subs ~ ., method = \"bstSm\", data = trainres)   \npredbsSm <- predict(modbsSm, testres)\n\n```\n\nThe predictions with boosting models are:\n\n````{r message=FALSE,warning=FALSE}\nfore2<-data.frame(fore1,Pred_Bs_gam=predbsgam,Pred_Bs_cub=predbscub,\n                  Pred_Bs_Sm=predbsSm)\nfore2\n````\n\n````{r echo=FALSE,message=FALSE,warning=FALSE}\n#Subscribers\nplot(testres,xlab=\"Years\",ylab=\"Subscribers\",col=\"blue\",main=\"Boosting Models\")\nlines(testing,lwd=1,col=\"blue\")\n\n#Boosted Generalized Additive Model\nlines(testres$Year,predbsgam,lwd=2,col=\"mediumvioletred\")\n\n#Cubist\nlines(testres$Year,predbscub,lwd=2,col=\"orangered\")\n\n#Boosted Smoothing Spline\nlines(testres$Year,predbsSm,lwd=2,col=\"darkturquoise\")\n\n\nlegend(\"topleft\",legend=c(\"Subs\",\"Generalized Additive\",\"Cubist\"\n                          ,\"Smoothing Spline\"),col=c(\"blue\",\"mediumvioletred\"\n                          ,\"orangered\",\"darkturquoise\"),lty=1,lwd=2)\n```\n\n\n##3. Predicting with Growth curves\nSimple random sampling of time series is probably not the best way to resample times series data. Hyndman and Athanasopoulos (2013)) discuss rolling forecasting origin techniques that move the training and test sets in time .\n\n````{r}\ntssubs<-ts(data_subs$Internet_Res,start=2005,end=2014)\ntsset<-tssubs/1000000\n\ntstrain<-window(tssubs/1000000,start=2005,end=2011)\ntstest<-window(tssubs/1000000,start=2011,end=2014)       \n\nyear<-c(2005:2014)\nyears<-c(2005:2011)\nyears2<-c(2011:2014)\n\n````\n\n###Linear Model\n````{r message=FALSE,warning=FALSE}\nfitlm<-tslm(tstrain~trend)\nfitlm\n\npredlm<-forecast(fitlm, h=5)\n\nsummary(predlm)\n````\n\n###Parabolic Model\n````{r message=FALSE,warning=FALSE}\ntime<-1:10\nfitpar=lm(tsset ~ time + I(time^2))\n\npredpar<-predict(fitpar)\n````\n\n###Exponential Model\nIn this case turn the unit Million since this model had errors with the initial data set.\n\n````{r message=FALSE,warning=FALSE}\n#Exponential smoothing state space model\n\nfitexp <- ets(tstrain*1000000)\npredexp<-forecast(fitexp,h=5)\n\npredexp\n````\n\nPlots\n\n````{r}\npar(mfrow = c(2, 2))\n\nplot(tsset,lwd=2,main=\"Internet Subscribers \",ylab=\"Subscribers [Millones]\",col=\"chocolate4\")\n\nplot(tsset,lwd=1,main=\"Forecast from Parabolic model \",ylab=\"Subscribers [Millones]\",col=\"blue\")\nlines(year,predpar, col=\"red\",lwd=1) \n\nplot(predlm,main=\"Forecast from Linear model \",ylab=\"Subscribers [Millones]\")\nlines(tstest,lwd=1,col=\"orangered\")\n\nplot(predexp,main=\"Forecast from Exponential Model\",ylab=\"Subscribers\")\nlines(tstest,lwd=1,col=\"green2\")\n````\n\nThe predictions with growth curves are:\n\n````{r}\nset1<-data.frame(predlm)\nx<-set1$Point.Forecast\nset3<-data.frame(predexp)\ny<-set3$Point.Forecast\nz<-predpar[8:10]\n\nset2<-data.frame(Year=c(2012:2016),Linear=x,Exponencial=y/1000000)\nset4<-subset(set2,Year<=2014)\nfore3<-data.frame(set4,Parabolic=z)\nfore3\n````\n\n\n##4.Predicting with Logistic Model \n\n###Logistic Model\nUsing the **growthmodels** package, with the *logistic* function to get the logistic curve\n\n**Usage**\nlogistic(t, alpha, beta, k)\n\n**Arguments**\nt     time\nx     size\nalpha upper asymptote\nbeta  growth range\nk     growth rate\n\n````{r}\n\nparmlm<-as.list(fitlm$coeff)\n\nalpha<-2 #upper asymptote (M)\nbeta<- parmlm$\"(Intercept)\"  #0.2156 growth range (a)\nk<- parmlm$trend             #0.1581 growth rate (b)\n  \nfitlog <- logistic(1:10, alpha, beta, k)\n\nplot(year,fitlog,main=\"Forecast from Logistic model\",ylab=\"Subscribers [Millones]\")\nlines(year,fitlog,col=\"blue2\")\nlines(tstrain,lwd=1,col=\"brown2\")\nlines(tstest,lwd=1,col=\"brown2\")\n\nfore4<-data.frame(fore3,Logistic=fitlog[8:10])\nfore4\n\n````\n\n\n##5.Modelos Fisher Pry\nModel applied When substitution is driven by superior technology. The new product or service presents some technological advantage over the old one.\n\n````{r message=FALSE,warning=FALSE}\ntime<-(year-mean(year))*2\n\nparmlm<-as.list(fitlm$coeff)\n\na<- parmlm$\"(Intercept)\"  \nb<- parmlm$trend          \n\nfitpry<-1/(1+exp(-b*(time-a)))\n````\n\nThe shape curve **S** represents the adoption of the service, this is the market penetration.\n\n````{r message=FALSE,warning=FALSE}\n\nplot(year,fitpry,lwd=1,col=\"green2\", main=\"Fisher-Pry Curve\",sub=\"Penetration versus time\", xlab=\"Tiempo\",ylab=\"f\")\nlines(year,fitpry,lwd=2,col=\"green4\")\npoints(mean(year),0.5,lwd=2,col=\"blue3\",pch=4)\ntext(mean(year)+1, 0.5, \"(th,fh)\")\npoints(2014,1,lwd=2,col=\"blue3\",pch=4)\ntext(2014, 0.95, \"(to)\")\nabline(h=0.5,v=mean(year),lty=3,col=\"dodgerblue\")\n````\n\n*Simple substitution Model*\nIts \"take over time\" defined as the time required to go from f=0.1 to f=0.9. This is inversely proportional to alpha.\n\n**f/(1-f) = exp.2alpha(t-t0)**\n\nwhere:\nf= old technology fraction replaced by the new.\nalpha= 1/2 annual percentage growth in the early years.\nto= time when f is 1/2\n\nThis expression allows one to plot the substitution data in the form of f/(1-f),the resulting points as ilustrated follow:\n\n\n````{r message=FALSE,warning=FALSE}\nalpha<-2*0.5\nto<-mean(year)\ntdelta<-to-years\n\nmodpry<-exp(alpha*(years-to))\n\nplot(years,modpry,lwd=2,col=\"hotpink3\", main=\"Modelo Fisher Pry\", xlab=\"Tiempo\",ylab=\"f/1-f\")\nlines(years,modpry,lwd=2,col=\"coral4\")\nlines(tstrain,lty=3,lwd=1,col=\"orangered\")\n````\n\n\n##6.Modelos Bass Model\nThis model was developed by Frank Bass in 1969 and it consists of a simple differential equation that describes the process of how new products get adopted in a population.  The basic premise of the model is that adopters can be classified as innovators or as imitators and the speed and timing of adoption depends on their degree of innovativeness and the degree of imitation among adopters.\n\n**m** Total number of potential buyers of the new product\n**p** The coefficient of innovation\n**q** The coefficient of imitation\n\nIn order to test the model, linear regression estimates the parameters of the model \n\n````{r message=FALSE,warning=FALSE}\n\ntime<-(years-mean(years))*2\ntsset<-tssubs/1000000\n\nregpol= lm(tstrain ~ time + I(time^2))\n\nparm<-as.list(regpol$coeff)\n\na<-parm$\"(Intercept)\"  \nb<-parm$time*(1)           \nc<-parm$\"I(time^2)\"    \n\nPar<-data.frame(a=a,b=b,c=c)\nPar\n\n \n#Bass Model Coefficients\n\nP<-c\nQ<-b+P\nM<-a/P\n\n#M<-(-b-sqrt((b^2)-(4*a*c)))/(2*c)\n#P<-a/M\n#Q<--c*M\n\n\nCoeff<-data.frame(P=P,Q=Q,M=M)\nCoeff\n````\n\nThe coefficient p is called the coefficient of innovation, external influence or advertising effect. The coefficient q is called the coefficient of imitation, internal influence or word-of-mouth effect.\n\n\nThe Sales Growth Model for Durables are determinated by:\n\n**S(t) = Innovation effect + Imitation effect**\n\nwhere:\nS(t) Sales at time t\nInnovation effect = p * Remaining Potencial\nImitation effect = q * Adopters *Remaining Potential\nRemaining Potencial = Total Potential - Q Adopters\n\n\n````{r}\n#Remaining Potencial\nRem<-2-tstrain\n\n#Innovation effect\npe<-P*Rem\n\n#Imitation effect\nqe<-Q*tstrain*Rem\n\n#Sales at time t\n\nsales<-pe+qe\n\nplot(sales, main=\"Sales Growth Model for Durables\",lwd=2,lty=1,col=\"green3\")\nlines(tstrain,col=\"orangered\")\n\n````\n\nThe Bass Model proposes that the likelihood that someone in the population will\npurchase a new product at a particular time t given that she has not already\npurchased the product until then, is summarized by the following simplification mathematical.\n\n**n(t) = pm + (q - p) [N(t)] -q/m * [N(t)]2**\n\nwhere:\nn(t) = basic diffusion equation for predicting new product sales\nN(t) = Adopters at time t\n\n````{r message=FALSE,warning=FALSE}\n\nter1<-P*M\nter2<-(Q-P)*tsset\nter3<-(Q/M)*tsset^2\n\nfitbas<-ter1+ter2-ter3\nfitbas\nplot(fitbas,ylab=\"n[t]\",col=\"hotpink3\",lwd=2,main=\"New product sales\")\n\n````\n\n\n##ComparaciÃ³n de Modelos\n\n````{r message=FALSE,warning=FALSE}\n\n#Modelo Lineal\nacc_a<-accuracy(predlm)\n#Modelo ParabÃ³lico\nacc_b<-accuracy(predpar,tsset)\n#Modelo Exponencial\nacc_c<-accuracy(predexp)\n#Modelo LogÃ­stico\nacc_d<-accuracy(fitlog,tsset)\n#Modelo Gompertz\n#acc_e<-accuracy(predgom)\n#Modelo Fisher-Pry\nacc_f<-accuracy(fitpry,tsset) #Duda\n#Modelo Bass\nacc_g<-accuracy(fitbas,tsset)        #Duda\n\n#Extract ME,RMSE, MAE, MPE, MAPE\nacca<-acc_a[1,1:5]\naccb<-acc_b[1,1:5]\naccc<-acc_c[1,1:5]\naccd<-acc_d[1,1:5]\naccf<-acc_f[1,1:5]\naccg<-acc_g[1,1:5]\n\nacc_all<-rbind(acca,accb,accc,accd,accf,accg)\nModelos<-c(\"Linear\",\"Parabolic\", \"Exponential\"\n          ,\"Logistic\",\"Fisher-Pry\",\"Bass\")\n\nperform<-data.frame(Modelos,acc_all)\n\nperform\n\n````\n\nExtract parameters model\n\n````{r echo=FALSE,message=FALSE,warning=FALSE}\np1<-as.list(fitlm$coeff)\np2<-as.list(fitpar$coeff)\n\na1<-round(p1$\"(Intercept)\",3)  \nb1<-round(p1$trend,3)           \n\na2<-round(p2$\"(Intercept)\",3)  \nb2<-round(p2$time,3)           \nc2<-round(p2$\"I(time^2)\",3)    \n\np<-round(P,3)\nq<-round(Q,3)\nm<-round(M,3)\n\na_all<-rbind(a1,a2,\"NA\",\"NA\",a1,a2)\nb_all<-rbind(b1,b2,\"NA\",\"NA\",b1,b2)\nc_all<-rbind(\"NA\",c2,\"NA\",\"NA\",\"NA\",c2)\np_all<-rbind(\"NA\",\"NA\",\"NA\",\"NA\",\"NA\",p)\nq_all<-rbind(\"NA\",\"NA\",\"NA\",\"NA\",\"NA\",q)\nm_all<-rbind(\"NA\",\"NA\",\"NA\",\"NA\",\"NA\",m)\n\n\nparamet<-data.frame(Modelos,a=a_all,b=b_all,c=c_all,p=p_all,q=q_all,m=m_all)\n\nparamet\n````\n\nWrite  performance of the models  in a **csv** file\n\n\n````{r}\nwrite.csv(perform,\"Performance_models.csv\")\n````\n",
    "created" : 1416340489018.000,
    "dirty" : false,
    "encoding" : "ISO8859-1",
    "folds" : "",
    "hash" : "1342387702",
    "id" : "67FE1021",
    "lastKnownWriteTime" : 1418525546,
    "path" : "~/GitHub/Dimensionamiento-de-Redes/Actividad 1/Forecasting.RMD",
    "project_path" : null,
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_markdown"
}